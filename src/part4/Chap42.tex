\chapter{Évaluation du protocole de recherche}




L’étude repose sur une comparaison des performances entre différentes stratégies
d’apprentissage (zero-shot, few-shot et fine-tuning). L’utilisation de
benchmarks standards et une évaluation rigoureuse garantissent la validité des
résultats. Cependant, certaines limites sont à noter :



\begin{itemize}

 \item \textbf{Généralisation
     des modèles} : Les performances des modèles Transformers
     restent influencées par la nature des données d’entraînement. L’article ne
     discute pas suffisamment l’impact potentiel des biais sur les résultats
     obtenus.

 \item \textbf{Dépendance
     aux données d'entraînement} : Les conclusions de l’étude pourraient ne pas
     être applicables à d’autres langages de programmation ou environnements,
     limitant ainsi leur portée.

 \item \textbf{Performance
     en conditions réelles} : L’intégration des modèles dans des
     environnements de développement (IDE) pourrait rencontrer des défis
     pratiques non abordés, tels que la latence du traitement et l’adoption par
     les développeurs.

\end{itemize}



